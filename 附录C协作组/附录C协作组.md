# 附录C 协作组

## C.1. Introduction

Cooperative Groups 是 CUDA 9 中引入的 CUDA 编程模型的扩展，用于组织通信线程组。协作组允许开发人员表达线程通信的粒度，帮助他们表达更丰富、更有效的并行分解。

从历史上看，CUDA 编程模型为同步协作线程提供了一个单一、简单的构造：线程块的所有线程之间的屏障，如使用 `__syncthreads()` 内部函数实现的那样。但是，程序员希望以其他粒度定义和同步线程组，以“集体”组范围功能接口的形式实现更高的性能、设计灵活性和软件重用。为了表达更广泛的并行交互模式，许多面向性能的程序员已经求助于编写自己的临时和不安全的原语来同步单个 warp 中的线程，或者跨运行在单个 GPU 上的线程块集。虽然实现的性能改进通常很有价值，但这导致了越来越多的脆弱代码集合，随着时间的推移和跨 GPU 架构的不同，这些代码的编写、调整和维护成本很高。合作组通过提供安全且面向未来的机制来启用高性能代码来解决这个问题。

## C.2. What's New in CUDA 11.0

* 使用网格范围的组不再需要单独编译，并且同步该组的速度现在提高了 `30%`。此外，我们在最新的 Windows 平台上启用了协作启动，并在 MPS 下运行时增加了对它们的支持。
* `grid_group `现在可以转换为 `thread_group`。
* 线程块切片和合并组的新集合：`reduce` 和 `memcpy_async`。
* 线程块切片和合并组的新分区操作：`labeled_pa​​rtition` 和 `binary_partition`。
* 新的 API，`meta_group_rank` 和 `meta_group_size`，它们提供有关导致创建该组的分区的信息。
* 线程块`tile`现在可以在类型中编码其父级，这允许对发出的代码进行更好的编译时优化。
* 接口更改：`grid_group` 必须在声明时使用 `this_grid()` 构造。默认构造函数被删除。
  

注意：在此版本中，我们正朝着要求 C++11 提供新功能的方向发展。在未来的版本中，所有现有 API 都需要这样做。

## C.3. Programming Model Concept
协作组编程模型描述了 CUDA 线程块内和跨线程块的同步模式。 它为应用程序提供了定义它们自己的线程组的方法，以及同步它们的接口。 它还提供了强制执行某些限制的新启动 API，因此可以保证同步正常工作。 这些原语在 CUDA 内启用了新的协作并行模式，包括生产者-消费者并行、机会并行和整个网格的全局同步。

合作组编程模型由以下元素组成：
* 表示协作线程组的数据类型；
* 获取由 CUDA 启动 API 定义的隐式组的操作（例如，线程块）；
* 将现有群体划分为新群体的集体；
* 用于数据移动和操作的集体算法（例如 `memcpy_async、reduce、scan`）；
* 同步组内所有线程的操作；
* 检查组属性的操作；
* 公开低级别、特定于组且通常是硬件加速的操作的集合。







